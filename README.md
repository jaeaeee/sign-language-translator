# 🤟 실시간 수어 번역 프로그램

카메라를 통해 사용자의 수어 동작을 실시간으로 인식하고,  
학습된 모델을 통해 해당 수어를 텍스트(한글)로 변환하여 출력하는  
**수어 인식 기반 텍스트 번역 프로그램**

---

## 🎯 목표

- 실시간 수어 → 텍스트 변환을 통해 농인과 비농인 간의 **언어 장벽 해소**
- 공공기관, 병원, 민원창구 등 **실제 사용 가능한 수어 통역 보조 시스템** 개발
- 향후 다국어 텍스트 변환 기능으로 **외국인 농인 사용자까지 확장**

---

## ❓ 해결하고자 하는 문제

- 수어 통역사의 부족 및 비용/시간 문제로 인해 **농인의 일상 소통에 제약**
- 기존 자막 시스템은 수어 입력을 인식하지 못해 **양방향 소통이 불가능**
- **실시간 수어 인식 기반 시스템**을 통해 농인의 정보 접근성 향상

---

## 🛠 주요 기능

- 웹캠을 통해 사용자의 **수어 영상 실시간 입력**
- **AI-Hub 수어 데이터셋**을 기반으로 학습된 모델로 손동작 인식
- 인식된 수어를 **단어 수준 텍스트(한글)**로 출력
- 추후 **문장 단위 인식** 및 **다국어 번역 기능** 확장 예정
- 모델 개발: **OpenCV**, **Mediapipe**, **TensorFlow or PyTorch**
- 출력 방식: **PyQt (로컬 GUI)** 또는 **Flask (웹 화면)**

---

## 🧠 시스템 구성도 (계획)

```
[Webcam Input]
        ↓
[수어 인식 모듈: Mediapipe / YOLO / OpenCV]
        ↓
[수어 → 텍스트 변환: AI-Hub 학습 모델]
        ↓
[텍스트 출력 및 다국어 번역: Flask / PyQt + 번역기]
```

---

## ⚙️ 사용 기술 (예정)

- **언어:** Python
- **영상처리:** OpenCV, Mediapipe, YOLO
- **딥러닝:** TensorFlow or PyTorch
- **출력/UI:** Flask, PyQt
- **개발환경:** Google Colab
- **데이터셋:** AI-Hub 수어 데이터

---

## 🗓️ 진행 현황

- [x] 아이디어 및 기획 확정
- [x] 중간보고서 제출
- [x] 기술 스택/구조 설계
- [ ] 수어 데이터 전처리
- [ ] 단어 인식 모델 학습
- [ ] 텍스트 출력 기능 개발
- [ ] UI 설계 및 다국어 번역 연동

---
